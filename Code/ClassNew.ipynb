{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split \n",
    "from keras import losses, metrics \n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class_train = pd.read_csv(\"../Data/TrainandTestDataset.csv\") \n",
    "Class_train_suffled = shuffle(Class_train, random_state=2)\n",
    "Class_train_suffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = [\"Ia\", \"Ib\", \"Ic\", \"Va\", \"Vb\", \"Vc\"] \n",
    "target_col = [\"LG\", \"LL\", \"LLG\", \"LLL\", \"None\"]\n",
    "X = Class_train_suffled[features_col] \n",
    "Y = Class_train_suffled[target_col] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalling = StandardScaler()\n",
    "X_scalled = scalling.fit_transform(X, Y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val  = train_test_split(X_scalled, Y, test_size=0.2, random_state=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class_model = keras.Sequential([\n",
    "    layers.Dense(60, activation='relu', input_shape=[6]),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(100, activation='relu'), \n",
    "    layers.Dense(50, activation='relu'),   \n",
    "    layers.Dense(5, activation = 'softmax')     \n",
    "])\n",
    "\n",
    "Class_model.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['categorical_accuracy'], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = Class_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data = (x_val, y_val),\n",
    "    batch_size = 600,  \n",
    "    epochs = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['categorical_accuracy', 'val_categorical_accuracy']].plot(); \n",
    "history_df.loc[:, ['loss', 'val_loss']].plot()\n",
    "print(\"Max train accuracy: {}\".format(history_df['categorical_accuracy'].max()))\n",
    "print(\"Max validation accuracy: {}\".format(history_df['val_categorical_accuracy'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Class_model.predict(x_val)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    a = y_pred[i, :]\n",
    "    val = np.max(a)\n",
    "    a[a != val] = 0\n",
    "    a[a == val] = 1  \n",
    "    y_pred[i, :] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(y_pred.shape[0]): \n",
    "    if np.sum(y_val.iloc[i,:]==y_pred[i,:]) == 5:    \n",
    "        correct = correct + 1\n",
    "accuracy = correct / y_val.shape[0]\n",
    "print(f\"Validation Accuracy = {accuracy*100}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truelabel = []\n",
    "predlabel = []\n",
    "\n",
    "for i in range(y_val.shape[0]):\n",
    "    if y_val.iloc[i, 0] == 1: \n",
    "        truelabel.append(\"LG\")\n",
    "    if y_val.iloc[i, 1] == 1:\n",
    "        truelabel.append(\"LL\")\n",
    "    if y_val.iloc[i, 2] == 1:\n",
    "        truelabel.append(\"LLG\") \n",
    "    if y_val.iloc[i, 3] == 1:\n",
    "        truelabel.append(\"LLL\")\n",
    "    if y_val.iloc[i, 4] == 1:\n",
    "        truelabel.append(\"None\") \n",
    "truelabel = np.array(truelabel) \n",
    "\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_pred[i, 0] == 1: \n",
    "        predlabel.append(\"LG\")\n",
    "    if y_pred[i, 1] == 1:\n",
    "        predlabel.append(\"LL\")\n",
    "    if y_pred[i, 2] == 1:\n",
    "        predlabel.append(\"LLG\") \n",
    "    if y_pred[i, 3] == 1:\n",
    "        predlabel.append(\"LLL\")\n",
    "    if y_pred[i, 4] == 1:\n",
    "        predlabel.append(\"None\") \n",
    "\n",
    "truelabel = np.array(truelabel) \n",
    "predlabel = np.array(predlabel) \n",
    "\n",
    "#Generate the confusion matrix\n",
    "cf_matrix = confusion_matrix(truelabel, predlabel)\n",
    "\n",
    "print(f\"Confusion Matrix on Validation Data:\\n{cf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('default'):\n",
    "    \n",
    "    figure(figsize=(7, 5), dpi=100)\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cf_matrix.flatten()]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                        cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in\n",
    "            zip(group_counts,group_percentages)]\n",
    "\n",
    "    labels = np.asarray(labels).reshape(5,5)\n",
    "\n",
    "    ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='crest')\n",
    "\n",
    "    ax.set_xlabel('\\nPredicted Fault Type\\n', fontsize = 12)\n",
    "    ax.set_ylabel('\\nActual Fault Type', fontsize = 13);\n",
    "\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels([\"LG\", \"LL\", \"LLG\", \"LLL\", \"None\"])\n",
    "    ax.yaxis.set_ticklabels([\"LG\", \"LL\", \"LLG\", \"LLL\", \"None\"])\n",
    "\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea3bc4447bd6cba55cdf9eaaee12c649a8a0a3c578f041a6381858bf23126293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
